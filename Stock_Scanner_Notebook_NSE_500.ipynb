{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to query data from google spreadsheet as a pandas dataframe\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient import discovery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('stock-scanner-project-75f48f4873c1.json',scope)\n",
    "service = discovery.build('sheets', 'v4', credentials=credentials)\n",
    "gs = service.spreadsheets()\n",
    "spreadsheet_id  = \"1yGCigPgAQUggnkg2qlOhHxHwEnH2fjfcheBgJsNi-5Q\"\n",
    "# sheet = gs.values().get(spreadsheetId = spreadsheet_id, range = range_, valueRenderOption = 'FORMULA').execute()\n",
    "# df_values = pd.DataFrame(sheet.get('values')[0:],columns=sheet.get('values')[0])\n",
    "# df_values = df_values[1:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads sheet 'NSE Holidays' from spreadsheet 'Stock_Scanner_Python'\n",
    "nse_holidays_sheet = gs.values().get(spreadsheetId = spreadsheet_id, \n",
    "                                     range = \"NSE Holidays\", \n",
    "                                     valueRenderOption = 'FORMULA',\n",
    "                                     dateTimeRenderOption = 'FORMATTED_STRING').execute()\n",
    "df_nse_holidays = pd.DataFrame(nse_holidays_sheet.get('values')[0:],columns=nse_holidays_sheet.get('values')[0])\n",
    "df_nse_holidays = df_nse_holidays[1:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "nse_holidays = [dt.datetime.strptime(date, \"%d-%b-%Y\").date() for date in df_nse_holidays['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from nsepy import get_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 11, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get previous trading day\n",
    "from datetime import date, timedelta\n",
    "def prev_weekday(adate):\n",
    "    adate -= timedelta(days=1)\n",
    "    while ((adate.weekday() > 4) & (adate not in nse_holidays)):\n",
    "        # Mon-Fri are 0-4 #also add holidays to this\n",
    "        adate -= timedelta(days=1)\n",
    "    return adate\n",
    "\n",
    "prev_weekday(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dates = pd.read_csv(\"stock_split_dates.csv\")\n",
    "split_dates['Split_Day'] = pd.to_datetime(split_dates['Split_Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_prev_weekday_split_date(prev_weekday,stock_name):\n",
    "    stock_name = stock_name.upper()\n",
    "    try:\n",
    "        split_date = dt.datetime.strptime(split_dates.loc[split_dates['Name']==stock_name,\n",
    "                                     'Split_Day'].values[0].astype(str).split(sep = 'T')[0], \n",
    "                     \"%Y-%m-%d\")\n",
    "        split_date = dt.datetime.date(split_date)\n",
    "        prev_weekday = max(prev_weekday,split_date)\n",
    "        return(prev_weekday)\n",
    "        print(split_date)\n",
    "        print(prev_weekday)\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        return(prev_weekday)\n",
    "#         return(prev_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_(dataframe,days = 20):\n",
    "    dataframe['Trend+'] = (dataframe['Smooth_+DX']>dataframe['Smooth_-DX']).astype(int)\n",
    "    dataframe['Trend-'] = (dataframe['Smooth_-DX']>dataframe['Smooth_+DX']).astype(int)\n",
    "    if(np.sum(dataframe['Trend+'])==len(dataframe['Trend+'])):\n",
    "        return('uptrend')\n",
    "    elif(np.sum(dataframe['Trend-'])==len(dataframe['Trend-'])):\n",
    "        return('downtrend')\n",
    "    else:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock):\n",
    "    stock = stock.lower()\n",
    "    \n",
    "    if(stock == 'banknifty'):\n",
    "        stock = 'NIFTY Bank'\n",
    "        a = get_history(symbol=stock, \n",
    "                        start=prev_weekday(date.today())-timedelta(weeks=52),\n",
    "                        end=date.today(),\n",
    "                        index = True)\n",
    "        a['Prev Close'] = a['Close'].shift(periods=1)\n",
    "        a['Stock Name'] = stock\n",
    "\n",
    "    elif(stock == 'nifty'):\n",
    "        stock = 'NIFTY 50'\n",
    "        a = get_history(symbol=stock, \n",
    "                        start=prev_weekday(date.today())-timedelta(weeks=52),\n",
    "                        end=date.today(),\n",
    "                        index = True)\n",
    "        a['Prev Close'] = a['Close'].shift(periods=1)\n",
    "        a['Stock Name'] = stock\n",
    "\n",
    "    else:\n",
    "        a = get_history(symbol=stock, \n",
    "                        start=max_prev_weekday_split_date(prev_weekday(date.today())-timedelta(weeks=52),\n",
    "                                                          stock.upper()),\n",
    "                        end=date.today())\n",
    "        if(a.shape[0] == 0):\n",
    "            a = get_history(symbol=stock.upper(), \n",
    "                            start=max_prev_weekday_split_date(prev_weekday(date.today())-timedelta(weeks=52),stock.upper()),\n",
    "                            end=date.today())\n",
    "        a['Stock Name'] =stock.upper()\n",
    "    \n",
    "    a = a[['Stock Name','Open','High','Low','Close','Prev Close','Volume']]\n",
    "    a['high_minus_low'] = a['High'] - a['Low']\n",
    "    a['high_minus_prev_close'] = a['High'] - a['Prev Close']\n",
    "    a['low_minus_prev_close'] = a['Low'] - a['Prev Close']\n",
    "    a['True_Range'] = a[['high_minus_low','high_minus_prev_close','low_minus_prev_close']].max(axis=1)\n",
    "    a['ATR'] = a['True_Range'].rolling(window = 14, min_periods= 14).mean()\n",
    "    a['Prev High'] = a['High'].shift(1)\n",
    "    a['High_minus_Prev_High'] = a['High'] - a['Prev High']\n",
    "    a['Prev Low'] = a['Low'].shift(1)\n",
    "    a['Prev_Low_minus_Low'] = a['Prev Low'] - a['Low']\n",
    "    a['+DX'] = a.apply(lambda x: x['High_minus_Prev_High'] if((x['High_minus_Prev_High']>x['Prev_Low_minus_Low']) & \n",
    "                                                              (x['High_minus_Prev_High']>0)) else 0, axis = 1)\n",
    "    a['-DX'] = a.apply(lambda x: x['Prev_Low_minus_Low'] if((x['Prev_Low_minus_Low']>x['High_minus_Prev_High']) & \n",
    "                                                            (x['Prev_Low_minus_Low']>0)) else 0, axis = 1)\n",
    "    a['Smooth_+DX'] = a['+DX'].rolling(window = 14, min_periods = 14).mean()\n",
    "    a['Smooth_-DX'] = a['-DX'].rolling(window = 14, min_periods = 14).mean()\n",
    "    a['+DMI'] = a['Smooth_+DX']/a['ATR']\n",
    "    a['-DMI'] = a['Smooth_-DX']/a['ATR']\n",
    "    a['DX'] = np.abs(a['+DMI']-a['-DMI'])*100.0/(a['+DMI']+a['-DMI'])\n",
    "    a['ADX'] = a['DX'].rolling(window = 14, min_periods = 14).mean()\n",
    "    trend_stock = trend_(a.tail(20))\n",
    "    b = a.iloc[-1]\n",
    "    b['Trend'] = trend_stock\n",
    "    b['20_D_Avg_Vol'] = np.average(a.tail(20)['Volume'])\n",
    "    b['10_D_Avg_Vol'] = np.average(a.tail(10)['Volume'])\n",
    "    b['5_D_Avg_Vol'] = np.average(a.tail(5)['Volume'])\n",
    "    \n",
    "#     b['50_D_Avg_P'] = np.average(a.tail(50)['Price'])\n",
    "#     b['20_D_Avg_P'] = np.average(a.tail(20)['Price'])\n",
    "#     b['5_D_Avg_P'] = np.average(a.tail(5)['Price'])\n",
    "\n",
    "    b['200_D_Avg_Close'] = np.average(a.tail(200)['Close'])\n",
    "    b['50_D_Avg_Close'] = np.average(a.tail(50)['Close'])\n",
    "    b['20_D_Avg_Close'] = np.average(a.tail(20)['Close'])\n",
    "    b['5_D_Avg_Close'] = np.average(a.tail(5)['Close'])\n",
    "    \n",
    "    b['Prv_200_D_Avg_Close'] = np.average(a.tail(201)[1:200]['Close'])\n",
    "    b['Prv_50_D_Avg_Close'] = np.average(a.tail(51)[1:50]['Close'])\n",
    "    b['Prv_20_D_Avg_Close'] = np.average(a.tail(21)[1:20]['Close'])\n",
    "\n",
    "    \n",
    "    b['120_D_Max_Close'] = np.max(a.tail(120)['Close'])\n",
    "    b['20_D_Max_Close'] = np.max(a.tail(20)['Close'])\n",
    "    b['5_D_Max_Close'] = np.average(a.tail(5)['Close'])\n",
    "\n",
    "    b['Yr_H_Price'] = np.max(a['High'])\n",
    "    b['Yr_L_Price'] = np.min(a['Low'])\n",
    "    b['Yr_H_Vol'] = np.max(a['Volume'])\n",
    "    b['Yr_L_Vol'] = np.min(a['Volume'])\n",
    "    \n",
    "    b['Prv_Yr_H_Price'] = np.max(a[:-1]['High'])\n",
    "    b['Prv_Yr_L_Price'] = np.min(a[:-1]['Low'])\n",
    "    b['Prv_Yr_H_Vol'] = np.max(a[:-1]['Volume'])\n",
    "    b['Prv_Yr_L_Vol'] = np.min(a[:-1]['Volume'])\n",
    "    \n",
    "    b['Prv_2_Close'] = a.iloc[-3]['Close']\n",
    "    b['Prv_3_Close'] = a.iloc[-4]['Close']\n",
    "    \n",
    "    b['Prv_1_Open'] = a.iloc[-2]['Open']\n",
    "    b['Prv_2_Open'] = a.iloc[-3]['Open']\n",
    "    b['Prv_3_Open'] = a.iloc[-4]['Open']\n",
    "\n",
    "    b['Prv_1_Low'] = a.iloc[-2]['Low']\n",
    "    b['Prv_2_Low'] = a.iloc[-3]['Low']\n",
    "    b['Prv_3_Low'] = a.iloc[-4]['Low']\n",
    "    b['Prv_4_Low'] = a.iloc[-5]['Low']\n",
    "    b['Prv_5_Low'] = a.iloc[-6]['Low']\n",
    "    b['Prv_6_Low'] = a.iloc[-7]['Low']\n",
    "    b['Prv_7_Low'] = a.iloc[-8]['Low']\n",
    "    b['Prv_8_Low'] = a.iloc[-9]['Low']\n",
    "    b['10_D_Min_Low'] = np.min(a.tail(10)['Low'])\n",
    "    b['50_D_Min_Low'] = np.min(a.tail(50)['Low'])\n",
    "\n",
    "    b['Prv_1_High'] = a.iloc[-2]['High']\n",
    "    b['Prv_2_High'] = a.iloc[-3]['High']\n",
    "    b['Prv_3_High'] = a.iloc[-4]['High']\n",
    "    b['Prv_4_High'] = a.iloc[-5]['High']\n",
    "    b['Prv_5_High'] = a.iloc[-6]['High']\n",
    "    b['Prv_6_High'] = a.iloc[-7]['High']\n",
    "    b['Prv_7_High'] = a.iloc[-8]['High']\n",
    "    b['Prv_8_High'] = a.iloc[-9]['High']\n",
    "    b['10_D_Max_High'] = np.max(a.tail(10)['High'])\n",
    "    b['50_D_Max_High'] = np.max(a.tail(50)['High'])\n",
    "    \n",
    "    b['100_D_Avg_Range'] = np.mean(a.tail(100)['High']-a.tail(100)['Low'])\n",
    "    b['Prev_Volume'] = a.iloc[-2]['Volume']\n",
    "    \n",
    "    b = pd.DataFrame(b.T.reset_index().T.values[1:],columns = b.T.reset_index().T.values[0])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nifty F&O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 11, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Series</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>Trades</th>\n",
       "      <th>Deliverable Volume</th>\n",
       "      <th>%Deliverble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>225.60</td>\n",
       "      <td>226.00</td>\n",
       "      <td>226.85</td>\n",
       "      <td>221.70</td>\n",
       "      <td>222.75</td>\n",
       "      <td>222.45</td>\n",
       "      <td>223.82</td>\n",
       "      <td>17843327</td>\n",
       "      <td>3.993623e+14</td>\n",
       "      <td>119495</td>\n",
       "      <td>11487403</td>\n",
       "      <td>0.6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>222.45</td>\n",
       "      <td>224.85</td>\n",
       "      <td>227.30</td>\n",
       "      <td>224.00</td>\n",
       "      <td>227.15</td>\n",
       "      <td>226.55</td>\n",
       "      <td>225.88</td>\n",
       "      <td>7024796</td>\n",
       "      <td>1.586768e+14</td>\n",
       "      <td>106228</td>\n",
       "      <td>4126838</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>226.55</td>\n",
       "      <td>229.70</td>\n",
       "      <td>230.70</td>\n",
       "      <td>225.70</td>\n",
       "      <td>229.65</td>\n",
       "      <td>229.80</td>\n",
       "      <td>228.22</td>\n",
       "      <td>20270558</td>\n",
       "      <td>4.626148e+14</td>\n",
       "      <td>168607</td>\n",
       "      <td>9872907</td>\n",
       "      <td>0.4871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>229.80</td>\n",
       "      <td>229.85</td>\n",
       "      <td>230.90</td>\n",
       "      <td>227.85</td>\n",
       "      <td>228.85</td>\n",
       "      <td>228.75</td>\n",
       "      <td>229.11</td>\n",
       "      <td>11520817</td>\n",
       "      <td>2.639533e+14</td>\n",
       "      <td>131594</td>\n",
       "      <td>5224823</td>\n",
       "      <td>0.4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>228.75</td>\n",
       "      <td>227.45</td>\n",
       "      <td>232.85</td>\n",
       "      <td>227.20</td>\n",
       "      <td>230.75</td>\n",
       "      <td>230.85</td>\n",
       "      <td>230.52</td>\n",
       "      <td>13431108</td>\n",
       "      <td>3.096183e+14</td>\n",
       "      <td>110805</td>\n",
       "      <td>4693940</td>\n",
       "      <td>0.3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-11</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>230.85</td>\n",
       "      <td>230.40</td>\n",
       "      <td>231.50</td>\n",
       "      <td>228.55</td>\n",
       "      <td>230.20</td>\n",
       "      <td>230.00</td>\n",
       "      <td>229.65</td>\n",
       "      <td>8134962</td>\n",
       "      <td>1.868180e+14</td>\n",
       "      <td>96104</td>\n",
       "      <td>3356619</td>\n",
       "      <td>0.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>230.00</td>\n",
       "      <td>231.20</td>\n",
       "      <td>233.95</td>\n",
       "      <td>229.15</td>\n",
       "      <td>232.85</td>\n",
       "      <td>232.90</td>\n",
       "      <td>231.88</td>\n",
       "      <td>11855531</td>\n",
       "      <td>2.749079e+14</td>\n",
       "      <td>99013</td>\n",
       "      <td>4459244</td>\n",
       "      <td>0.3761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-15</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>232.90</td>\n",
       "      <td>233.95</td>\n",
       "      <td>239.00</td>\n",
       "      <td>233.10</td>\n",
       "      <td>238.15</td>\n",
       "      <td>238.10</td>\n",
       "      <td>236.77</td>\n",
       "      <td>38755267</td>\n",
       "      <td>9.176154e+14</td>\n",
       "      <td>176533</td>\n",
       "      <td>21205338</td>\n",
       "      <td>0.5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-16</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>238.10</td>\n",
       "      <td>239.05</td>\n",
       "      <td>239.65</td>\n",
       "      <td>235.00</td>\n",
       "      <td>235.25</td>\n",
       "      <td>235.45</td>\n",
       "      <td>237.36</td>\n",
       "      <td>14675969</td>\n",
       "      <td>3.483463e+14</td>\n",
       "      <td>97861</td>\n",
       "      <td>7990381</td>\n",
       "      <td>0.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-17</th>\n",
       "      <td>ITC</td>\n",
       "      <td>EQ</td>\n",
       "      <td>235.45</td>\n",
       "      <td>236.00</td>\n",
       "      <td>245.25</td>\n",
       "      <td>235.65</td>\n",
       "      <td>239.30</td>\n",
       "      <td>239.50</td>\n",
       "      <td>240.97</td>\n",
       "      <td>46697822</td>\n",
       "      <td>1.125290e+15</td>\n",
       "      <td>246949</td>\n",
       "      <td>15742715</td>\n",
       "      <td>0.3371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol Series  Prev Close    Open    High     Low    Last   Close  \\\n",
       "Date                                                                           \n",
       "2021-11-03    ITC     EQ      225.60  226.00  226.85  221.70  222.75  222.45   \n",
       "2021-11-04    ITC     EQ      222.45  224.85  227.30  224.00  227.15  226.55   \n",
       "2021-11-08    ITC     EQ      226.55  229.70  230.70  225.70  229.65  229.80   \n",
       "2021-11-09    ITC     EQ      229.80  229.85  230.90  227.85  228.85  228.75   \n",
       "2021-11-10    ITC     EQ      228.75  227.45  232.85  227.20  230.75  230.85   \n",
       "2021-11-11    ITC     EQ      230.85  230.40  231.50  228.55  230.20  230.00   \n",
       "2021-11-12    ITC     EQ      230.00  231.20  233.95  229.15  232.85  232.90   \n",
       "2021-11-15    ITC     EQ      232.90  233.95  239.00  233.10  238.15  238.10   \n",
       "2021-11-16    ITC     EQ      238.10  239.05  239.65  235.00  235.25  235.45   \n",
       "2021-11-17    ITC     EQ      235.45  236.00  245.25  235.65  239.30  239.50   \n",
       "\n",
       "              VWAP    Volume      Turnover  Trades  Deliverable Volume  \\\n",
       "Date                                                                     \n",
       "2021-11-03  223.82  17843327  3.993623e+14  119495            11487403   \n",
       "2021-11-04  225.88   7024796  1.586768e+14  106228             4126838   \n",
       "2021-11-08  228.22  20270558  4.626148e+14  168607             9872907   \n",
       "2021-11-09  229.11  11520817  2.639533e+14  131594             5224823   \n",
       "2021-11-10  230.52  13431108  3.096183e+14  110805             4693940   \n",
       "2021-11-11  229.65   8134962  1.868180e+14   96104             3356619   \n",
       "2021-11-12  231.88  11855531  2.749079e+14   99013             4459244   \n",
       "2021-11-15  236.77  38755267  9.176154e+14  176533            21205338   \n",
       "2021-11-16  237.36  14675969  3.483463e+14   97861             7990381   \n",
       "2021-11-17  240.97  46697822  1.125290e+15  246949            15742715   \n",
       "\n",
       "            %Deliverble  \n",
       "Date                     \n",
       "2021-11-03       0.6438  \n",
       "2021-11-04       0.5875  \n",
       "2021-11-08       0.4871  \n",
       "2021-11-09       0.4535  \n",
       "2021-11-10       0.3495  \n",
       "2021-11-11       0.4126  \n",
       "2021-11-12       0.3761  \n",
       "2021-11-15       0.5472  \n",
       "2021-11-16       0.5445  \n",
       "2021-11-17       0.3371  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## proceed only if this code returns latest data\n",
    "stock = \"itc\"\n",
    "get_history(symbol=stock, \n",
    "            start=max_prev_weekday_split_date(prev_weekday(date.today())-timedelta(weeks=2),\n",
    "                                              stock.upper()),\n",
    "            end=date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_f_n_o = pd.read_excel(\"stock_names.xlsx\",header=0,sheet_name=\"NSE F&O\")\n",
    "# nifty_500 = pd.read_excel(\"stock_names.xlsx\",header=0,sheet_name=\"NSE 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-cb05d1c43d4d>:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for stock in tqdm(stock_names):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134c5fa603ed49cdb10382529c91bd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_data_nse_f_n_o = pd.DataFrame(columns = ['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low'])\n",
    "\n",
    "# stock_names = nifty_500['NSE 500 Stocks']\n",
    "stock_names = nifty_f_n_o['NSE Futures 150 stocks']\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "for stock in tqdm(stock_names):\n",
    "    temp = get_stock_data(stock)\n",
    "    temp = temp[['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low']]\n",
    "    stock_data_nse_f_n_o=stock_data_nse_f_n_o.append(temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 56)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_nse_f_n_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_f_n_o_stocks_data = pd.merge(stock_data_nse_f_n_o, nifty_f_n_o, how='left', left_on=['Stock Name'], \n",
    "                                   right_on = [nifty_f_n_o.columns[0]])\n",
    "# # to convert dataframe to list for uploading to google sheet\n",
    "nifty_f_n_o_stocks_data = nifty_f_n_o_stocks_data[['Stock Name', 'Sector', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low']]\n",
    "nifty_f_n_o_stocks_data.replace(np.nan,'',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 57)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifty_f_n_o_stocks_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifty_f_n_o_stocks_data.to_excel(excel_writer=\"nifty_f_n_o_stocks_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to convert dataframe to list for uploading to google sheet\n",
    "nifty_f_n_o_stocks_data = nifty_f_n_o_stocks_data.T.reset_index().T.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1d10643bca88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## writing list to google sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response_data = service.spreadsheets().values().update(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mspreadsheetId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspreadsheet_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mvalueInputOption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'USER_ENTERED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NSE_Futures'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/googleapiclient/discovery.py\u001b[0m in \u001b[0;36mmethod\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         headers, params, query, body = model.request(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_path_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_query_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/googleapiclient/model.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, headers, path_params, query_params, body_value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbody_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mbody_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/googleapiclient/model.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, body_value)\u001b[0m\n\u001b[1;32m    273\u001b[0m         ):\n\u001b[1;32m    274\u001b[0m             \u001b[0mbody_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "## writing list to google sheet\n",
    "response_data = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='NSE_Futures',\n",
    "        body=dict(\n",
    "            majorDimension='ROWS',\n",
    "            values=nifty_f_n_o_stocks_data)\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing updated time to google sheet\n",
    "import datetime\n",
    "response_datetime = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='NSE_Futures!BF1',\n",
    "        body={\n",
    "            'values': [[datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')]]\n",
    "        }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nifty 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifty_f_n_o = pd.read_excel(\"stock_names.xlsx\",header=0,sheet_name=\"NSE F&O\")\n",
    "nifty_500 = pd.read_excel(\"stock_names.xlsx\",header=0,sheet_name=\"NSE 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "stock_data_nifty_500 = pd.DataFrame(columns = ['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low'])\n",
    "\n",
    "stock_names = nifty_500['NSE 500 Stocks']\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "for stock in tqdm(stock_names):\n",
    "    temp = get_stock_data(stock)\n",
    "    temp = temp[['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low']]\n",
    "    stock_data_nifty_500=stock_data_nifty_500.append(temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_500_stocks_data = pd.merge(stock_data_nifty_500, nifty_500, how='left', left_on=['Stock Name'], \n",
    "                                   right_on = [nifty_500.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to convert dataframe to list for uploading to google sheet\n",
    "nifty_500_stocks_data = nifty_500_stocks_data[['Stock Name', 'Sector', 'Open','High','Low','Close','Prev Close',\n",
    "                                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                     '50_D_Max_High','10_D_Max_High',\n",
    "                                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                     '100_D_Avg_Range',\n",
    "                                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                     'Volume','Prev_Volume',\n",
    "                                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                     'Prv_8_High','Prv_8_Low']]\n",
    "nifty_500_stocks_data.replace(np.nan,'',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifty_500_stocks_data[nifty_500_stocks_data['Stock Name']==\"CHOLAFIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to convert dataframe to list for uploading to google sheet\n",
    "nifty_500_stocks_data = nifty_500_stocks_data.T.reset_index().T.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifty_500_stocks_data.to_excel(excel_writer=\"nifty_500_stocks_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing list to google sheet\n",
    "response_data = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='NSE_500',\n",
    "        body=dict(\n",
    "            majorDimension='ROWS',\n",
    "            values=nifty_500_stocks_data)\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing updated time to google sheet\n",
    "import datetime\n",
    "response_datetime = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='NSE_500!BF1',\n",
    "        body={\n",
    "            'values': [[datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')]]\n",
    "        }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
